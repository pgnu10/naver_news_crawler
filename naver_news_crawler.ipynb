{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 키워드 \n",
    "search_keyword = '검색키워드를입력하세요'\n",
    "\n",
    "# 검색 기간\n",
    "start_day = '2022.11.01'\n",
    "end_day = '2022.12.01'\n",
    "\n",
    "# 검색 결과 정렬\n",
    "## 0: 관련도순, 1: 최신순, 2: 오래된순\n",
    "sorting = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리\n",
    "## 파일 로드\n",
    "import yaml\n",
    "import pandas as pd\n",
    "## 데이터 전처리\n",
    "import re\n",
    "## 크롤링\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "## 편의 기능\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naver_news_crawler(search_keyword, start_day, end_day, sorting, p_num=1):\n",
    "    search_keyword = search_keyword.replace(' ','%20')\n",
    "    title, link, date, press, content = [], [], [], [], []\n",
    "\n",
    "    while True:\n",
    "        url = f'https://search.naver.com/search.naver?where=news&sm=tab_pge&query={search_keyword}&sort={sorting}&photo=0&field=0&pd=3&ds={start_day}&de={end_day}&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:from{start_day.replace(\".\",\"\")}to{end_day.replace(\".\",\"\")},a:all&start={p_num}'\n",
    "        headers = { \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/98.0.4758.102\" }\n",
    "        original_html = requests.get(url, headers=headers)\n",
    "        html = BeautifulSoup(original_html.text, \"html.parser\")\n",
    "        check = html.find_all('div', attrs={'class':'not_found02'})\n",
    "        if check or p_num > 101:\n",
    "            break\n",
    "\n",
    "        hrefs = html.find_all('a', attrs={'class':'news_tit'})\n",
    "        date_infos = html.find_all('span', attrs={'class':'info'})\n",
    "        companies = html.find_all('a', attrs={'class':'info press'})\n",
    "        \n",
    "        title.extend(list(map(lambda x: x.text, hrefs)))\n",
    "        link.extend(list(map(lambda x: x.attrs['href'], hrefs)))\n",
    "        date.extend(list([date.text.strip('.') for date in date_infos if '면' not in date.text]))\n",
    "        press.extend(list(map(lambda x: x.text, companies)))\n",
    "        \n",
    "        p_num += 10\n",
    "\n",
    "    print(f\"{len(set(press))} 개의 언론사에서 총 {len(title)} 개의 뉴스 기사를 가져왔습니다.\")\n",
    "    if len(title) != len(set(title)):\n",
    "        print(f\"제목이 동일한 기사가 {len(title)-len(set(title))}개 있습니다. 중복에 주의하세요.\")\n",
    "    print(\"크롬 브라우저로 뉴스 기사 내용 크롤링을 시작합니다.\")\n",
    "\n",
    "    content = content_crawler(link)\n",
    "\n",
    "    news_df = pd.DataFrame({'title':title, 'date':date, 'press':press, 'content':content, 'link':link})\n",
    "    return news_df\n",
    "\n",
    "def content_crawler(link):\n",
    "    content = [] \n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install(), options=options)\n",
    "    driver.implicitly_wait(2)\n",
    "\n",
    "    for url in link:\n",
    "        driver.get(url)\n",
    "        time.sleep(2)\n",
    "\n",
    "        text = driver.find_element(By.XPATH, \"/html/body\").text\n",
    "        temp_ls = re.split('\\n\\n\\n\\n\\n+', text)\n",
    "        content.append(max(temp_ls, key=len))\n",
    "    driver.close()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{search_keyword}를 키워드로\")\n",
    "print(f\"{start_day}부터 {end_day}까지의 뉴스 기사를 크롤링 합니다.\")\n",
    "print('-'*70)\n",
    "\n",
    "news_df = naver_news_crawler(search_keyword, start_day, end_day, sorting)\n",
    "\n",
    "print(f\"크롤링 완료\\n{search_keyword}.csv에 저장합니다.\")\n",
    "news_df.to_csv(f\"{search_keyword}.csv\", encoding='utf-8-sig', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26ab672dbb0a5f54fd51bf1bce84c42a2c19e3465280a97c26769387c468ca57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
